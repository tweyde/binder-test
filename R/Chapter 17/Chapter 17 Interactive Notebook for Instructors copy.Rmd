---
title: "Chapter 17 Interactive Notebook for Instructors"
author: "Ram Gopal, Dan Philps, and Tillman Weyde"
date: '2022'
output:
  pdf_document:
    toc: yes
    toc_depth: '4'
  word_document:
    toc: yes
    toc_depth: '4'
  html_document:
    theme: united
    highlight: tango
    toc: yes
    toc_float: yes
    toc_depth: 4
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Loading the required packages and the Wine data file.
```{r}
library(caret)
library(rpart)
library(rattle)
print(names(wine))
print(nrow(wine))
```
## Training and Test Data set creation

```{r}
set.seed(0)
index = createDataPartition(wine$Type,p = 0.6,list = F)
train_wi <- wine[index,]
test_wi <- wine[-index,]
```

## Models offered in the Caret package
* It will be useful to show students all the models that the caret package supports. One can also easily see what hyper-parameters can be set for a model.

```{r}
# All the models supported by the caret package
modelnames <- paste(names(getModelInfo()), collapse=',  ')
modelnames
modelLookup(list('rpart'))
```

## Run DT algorithm and plot the tree

* Train the model
```{r}

tree = rpart(Type ~ ., data=train_wi, 
             control = rpart.control(maxdepth = 2))
fancyRpartPlot(tree)

```

* Predict on the test data.

```{r}

set.seed(0)
model_tree = rpart(Type ~ ., data=train_wi, control = rpart.control(maxdepth = 5))
predicted_dt = predict(model_tree, type = "class")
pred_test_dt = predict(model_tree, test_wi, type = "class")

paste("dt test:", confusionMatrix(reference = test_wi$Type, data = pred_test_dt)$overall[1], 
      "dt train:", confusionMatrix(reference = train_wi$Type, data = predicted_dt)$overall[1])

model_knn = knn3(train_wi,train_wi$Type)
predicted_knn <- predict(model_knn, train_wi, type = 'class')
pred_test_knn <- predict(model_knn, test_wi, type = 'class')

paste("knn test:", confusionMatrix(reference = test_wi$Type, data = pred_test_knn)$overall[1], 
      "knn train:", confusionMatrix(reference = train_wi$Type, data = predicted_knn)$overall[1])

```

* Create the confusion matrix for the training and test data
```{r}
# Performance on Test Data
confusionMatrix(reference = test_wi$Type, data = pred_test_knn, mode='everything', positive='MM')
# Performance on Training Data
confusionMatrix(reference = train_wi$Type, data = predicted_knn, mode='everything', positive='MM')

```

## Run KNN algorithm
* Check the hyper-parameter for KNN
```{r}
modelLookup('knn')
```

* Train and plot the KNN model. The plot indicates the best number of neighbors to use.
```{r}
model_knn= train(Type ~ ., data=train_wi, method='knn')
model_knn
plot(model_knn)
```

* Create the confusion matrix for the training and test data
```{r}
fitted <- predict(model_knn)
predicted <- predict(model_knn, test_wi)
# Performance on Test Data
confusionMatrix(reference = test_wi$Type, data = predicted)
# Performance on Training Data
confusionMatrix(reference = train_wi$Type, data = fitted)

```

* Get the overall model accuracy
```{r}
paste("KNN Test Accuracy = ",confusionMatrix(reference = test_wi$Type, data = predicted)$overall[1])

predicted = predict(tree,newdata = test_wi)
paste("DT Test Accuracy = ",confusionMatrix(reference = test_wi$Type, data = predicted)$overall[1])
```
## Cross-Validation

* 10-fold

```{r}
#install.packages("cvTools")
#library(cvTools) 
#folds = cvFolds(nrow(wine),K=10)
#wine2<-wine[sample(nrow(wine)),]

folds = createFolds(1:nrow(wine),k=10,list = TRUE)

```

```{r}

cross_val <- function(modl, data,nfolds) { # this assumes that the target is $Type
#  data<-data[sample(nrow(data)),]
  folds <- cut(seq(1,nrow(data)),breaks=nfolds,labels=FALSE)
  acc = c()
  for (i in 1:nfolds) {
    fold <- which(folds == i)
    train_folds <- data[-fold,]
    test_fold <- data[fold,]
    knn_fold = modl(train_folds,train_folds$Type,k = 5)
    k_f_p = predict(knn_fold,test_fold,type='class')
    acc[i] = sum(as.integer(k_f_p) == as.integer(test_fold$Type)) / nrow(test_fold)
  }
  return(acc)
}

```

```{r}
acc = cross_val(knn3, wine,10)
paste('10-fold-CV mean:',mean(acc),'sd:', sd(acc))

```

* 20-fold

```{r}
acc = cross_val(wine,20)
paste('20-fold-CV mean:',mean(acc),'sd:', sd(acc))
```

* LOOCV
```{r}
acc = cross_val(wine,nrow(wine))
paste('Leave-one-out-CV mean:',mean(acc),'sd:', sd(acc))
```

* Stratified Sampling

```{r}
model_knn_strat= train(Type ~ ., data=wine, method='knn',metric="Accuracy",
                    trControl=trainControl(method = 'cv',number = 20))
paste("Mean for stratified sample = ",mean(model_knn_strat$resample$Accuracy))
paste("sde for stratified sample = ",sd(model_knn_strat$resample$Accuracy))
```

## Signifance of Model Differences

* Compare 20-fold DT model with KNN model
```{r}
model_dt_cv_20= train(Type ~ ., data=wine, method='rpart',metric="Accuracy",
                    trControl=trainControl(method = 'cv',number = 20))
paste("Mean accuracy of KNN= ",mean(model_knn_cv_20$resample$Accuracy))
paste("Mean accuracy of DT = ",mean(model_dt_cv_20$resample$Accuracy))
wilcox.test(model_dt_cv_20$resample$Accuracy,model_knn_cv_20$resample$Accuracy)
```

* Compare Stratified CV DT model with KNN model

```{r}
folds = createMultiFolds(wine$Type, k = 20)
model_knn_strat= train(Type ~ ., data=wine, method='knn',metric="Accuracy",
                    trControl=trainControl(index = folds))
model_dt_strat= train(Type ~ ., data=wine, method='rpart',metric="Accuracy",
                    trControl=trainControl(index = folds))
paste("Mean accuracy KNN = ",mean(model_knn_strat$resample$Accuracy))
paste("Mean accuracy DT = ",mean(model_dt_strat$resample$Accuracy))
paste("sd accuracy KNN = ",sd(model_knn_strat$resample$Accuracy))
paste("sd accuracy DT = ",sd(model_dt_strat$resample$Accuracy))
wilcox.test(model_knn_strat$resample$Accuracy,model_dt_strat$resample$Accuracy)
```

# Hyperparameter tuning

* Decision Tree
```{r}
folds = createMultiFolds(train_wi$Type, k = 20)
model_dt_strat_fold= train(Type ~ ., data=train_wi, method='rpart2',metric="Accuracy",
                    trControl=trainControl(index = folds),
                    tuneGrid = expand.grid(maxdepth = 1:10))
folds = createMultiFolds(train_wi$Type, k = 2)
model_dt_strat_nofold= train(Type ~ ., data=train_wi, method='rpart2',metric="Accuracy",
                    trControl=trainControl(index = folds),
                    tuneGrid = expand.grid(maxdepth = 1:10))
```

* Plot

```{r}
df1 = model_dt_strat_nofold$results[,c(1,2)]
df1$foldtype = as.factor("Training")
df2 = model_dt_strat_fold$results[,c(1,2)]
df2$foldtype = as.factor("Cross-validation")
df = rbind(df1,df2)
ggplot(data=df,aes(x=maxdepth,y=Accuracy,color=foldtype))+
  geom_line()

```

* See and plot the final tree 
```{r}
model_dt_strat_fold$finalModel
fancyRpartPlot(model_dt_strat_fold$finalModel,main = "Decision Tree",sub = "")
```

## Estimating the Model Performance

* For 2 folds
```{r}
df = data.frame()
folds = createMultiFolds(train_wi$Type, k = 2)
for (md in 1:10){
model_dt_strat_nofold= train(Type ~ ., data=train_wi, method='rpart2',metric="Accuracy",trControl=trainControl(index = folds),
                    tuneGrid = expand.grid(maxdepth = md))
df = rbind(df,c(md,"Training",model_dt_strat_nofold$results$Accuracy))
pred = predict(model_dt_strat_nofold,newdata = test_wi)
t1 = table(test_wi$Type,pred)
accu = sum(t1[1,1]+t1[2,2]+t1[3,3])/nrow(test_wi)
df = rbind(df,c(md,"Validation",accu))
}
colnames(df) = c("maxdepth","foldtype","Accuracy")
```

* Plot
```{r}
df$maxdepth = as.numeric(df$maxdepth)
df$Accuracy = as.numeric(df$Accuracy)
ggplot(data=df,aes(x=maxdepth,y=Accuracy,color=foldtype))+
  geom_line()
```

* For 10 folds
```{r}

df = data.frame()
folds = createMultiFolds(train_wi$Type, k = 20)
for (md in 1:10){
  model_dt_strat_fold= train(Type ~ ., data=train_wi,  method='rpart2',metric="Accuracy",trControl=trainControl(index = folds),
                    tuneGrid = expand.grid(maxdepth = md))
df = rbind(df,c(md,"Training",model_dt_strat_fold$results$Accuracy))
pred = predict(model_dt_strat_fold,newdata = test_wi)
t1 = table(test_wi$Type,pred)
accu = sum(t1[1,1]+t1[2,2]+t1[3,3])/nrow(test_wi)
df = rbind(df,c(md,"Validation",accu))
}
colnames(df) = c("maxdepth","foldtype","Accuracy")
```

* Plot
```{r}
df$maxdepth = as.numeric(df$maxdepth)
df$Accuracy = as.numeric(df$Accuracy)

ggplot(data=df,aes(x=maxdepth,y=Accuracy,color=foldtype))+
  geom_line()
```

# Final Test of Performance

* Test accuracy for 2 folds
```{r}
folds = createMultiFolds(train_wi$Type, k = 2)
model_dt_strat_nofold= train(Type ~ ., data=train_wi, method='rpart2',metric="Accuracy",trControl=trainControl(index = folds),
                    tuneGrid = expand.grid(maxdepth = 3))
pred = predict(model_dt_strat_nofold,newdata = test_wi)
t1 = table(test_wi$Type,pred)
accu = sum(t1[1,1]+t1[2,2]+t1[3,3])/nrow(test_wi)
paste("Accuracy = ", accu)
```

* Performance of stratified CV

```{r}
folds = createMultiFolds(wine$Type, k = 20)
model_dt_strat_fold= train(Type ~ ., data=wine,  method='rpart2',metric="Accuracy",trControl=trainControl(index = folds),
                    tuneGrid = expand.grid(maxdepth = 3))
paste("CV Accuracy - Mean = ",mean(model_dt_strat_fold$resample$Accuracy))
paste("CV Accuracy - sd = ",sd(model_dt_strat_fold$resample$Accuracy))
```

