{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 16: Introduction to Machine Learning \n",
    "## Exercises solutions\n",
    "The dataset used in this chapter can be imported with the *Sklearn* *laod_iris()* function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the modules\n",
    "import sklearn\n",
    "from sklearn.datasets import load_iris \n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset and show its attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset type: \n",
      "<class 'sklearn.utils.Bunch'>\n",
      "\n",
      "Dataset attributes: \n",
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n",
      "\n",
      "Feaures names: \n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "\n",
      "Target names: \n",
      "['setosa' 'versicolor' 'virginica']\n",
      "\n",
      "Number of samples: \n",
      "150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "iris = load_iris() \n",
    "# we can see that this dataset is a class \n",
    "print(f'Dataset type: \\n{type(iris)}\\n')\n",
    "# and it has some functions and attributes that describe it\n",
    "print(f'Dataset attributes: \\n{iris.keys()}\\n')\n",
    "# these are our features (X)\n",
    "print(f'Feaures names: \\n{iris.feature_names}\\n')\n",
    "# these are the targets/labels (y)\n",
    "print(f'Target names: \\n{iris.target_names}\\n')\n",
    "# number of samples\n",
    "print(f'Number of samples: \\n{len(iris.data)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 \n",
    "Implement your own version of *train_test_split*, so that it generates three sets (train, validation, test). You should accept two arguments, train_size and validation_size. <br>\n",
    "You then need to internally determine the test_size. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There would be many ways to resolve this problem. In this implementation we use the inputs to generate random indexes to slice the arrays (sampling) and return *shuffled* train, validation and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, train_size, validation_size):\n",
    "    '''\n",
    "    Function: \n",
    "\n",
    "            Generates train, validation and test sets from arrays of features and targets.\n",
    "\n",
    "    Inputs: \n",
    "\n",
    "            X: array containing the features \n",
    "            y: array containing the targets/labels\n",
    "            train_size: percentage of data to be used for training (takes values beween 0-1)\n",
    "            validation_size: percentage of the remaining data (1 - tain_size) to be used for validating (takes values beween 0-1)\n",
    "\n",
    "    Outputs: \n",
    "\n",
    "             1. array of features for training of size: 'train_size' * len(data)\n",
    "             2. array of targets for training of size: 'train_size' * len(data)\n",
    "             3. array of features for validating of size: (1 - 'train_size') * 'validation_size' * len(data) \n",
    "             4. array of targets for validating of size: (1 - 'train_size') * 'validation_size' * len(data) \n",
    "             5. array of features for testing of size: (1 - 'train_size') * (1 - 'validation_size') * len(data) \n",
    "             6. array of targets for testing of size: (1 - 'train_size') * (1 - 'validation_size') * len(data) \n",
    "    '''\n",
    "    \n",
    "    # create a random index of integers \n",
    "    ind = random.sample(range(0, len(X)), int(len(X)*train_size))\n",
    "    #create a mask \n",
    "    mask = np.ones(len(X), dtype=bool)\n",
    "    mask[ind] = False\n",
    "    # slice the features for the trainig set by the indexes generated\n",
    "    X_train = X[ind]\n",
    "    # slice the features for the test set by the mask generated\n",
    "    X_test = X[mask] \n",
    "    # slice the tragets for the train set by the indexes generated\n",
    "    y_train = y[ind]\n",
    "    # slice the targets for the test set by the mask generated\n",
    "    y_test = y[mask] \n",
    "    # create index of integers \n",
    "    ind_2 = random.sample(range(0, len(X_test)), int(len(X_test)*validation_size)) \n",
    "    #create second mask \n",
    "    mask_2 = np.ones(len(X_test), dtype=bool)\n",
    "    mask_2[ind_2] = False\n",
    "    # slice the features for the validation set by the indexes generated\n",
    "    X_val = X_test[ind_2]\n",
    "    # slice the features for the test set by the mask generated\n",
    "    X_test = X_test[mask_2] \n",
    "    # slice the targets for the validation set by the indexes generated\n",
    "    y_val = y_test[ind_2]\n",
    "    # slice the targets for the test set by the mask generated\n",
    "    y_test = y_test[mask_2] \n",
    "    # return the sets\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing, complemented by the use of *masks* to extract the 'not-indexes', is computationally efficient, as demonstrated below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function running time: 0.0009377003\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# unpack the function varibales in the train, validation and test sets\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = train_test_split(iris.data, iris.target, train_size = 0.7, validation_size = 0.5)\n",
    "print(f'Function running time: {(time.time() - start):.10f}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print the number of samples in the training, validation and test sets to make sure we obtained the desired splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features for training: 105\n",
      "Number of targets for training: 105\n",
      "Number of features for validating: 22\n",
      "Number of targets for validating: 22\n",
      "Number of features for testing: 23\n",
      "Number of targets for testing: 23\n"
     ]
    }
   ],
   "source": [
    "# print the number of samples per dataset\n",
    "print(f'Number of features for training: {len(X_train)}')\n",
    "print(f'Number of targets for training: {len(y_train)}')\n",
    "print(f'Number of features for validating: {len(X_val)}')\n",
    "print(f'Number of targets for validating: {len(y_val)}')\n",
    "print(f'Number of features for testing: {len(X_test)}')\n",
    "print(f'Number of targets for testing: {len(y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we notice that, despite our dataset is originally balanced in its classes (33% of labels for each of the 3 target classes), in our test set we end up having just 4 samples of the first class, against 11 samples of class 2. This due to the randomness of our sampling, and usually something we would like to keep an eye on (or control) as it could negatively affect the learning of an algorythm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([ 4, 11,  8], dtype=int64))"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "What is a necessary condition for the arguments to the function created in execise 1 to be valid? Implement a test and print an error message if the arguments are not valid. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, given the dataset, we want to make sure that the received inputs are numpy arrays, that their features and targets arrays are of the same length and that the inputs sizes would generate reasonable sets. We present how to handle these basic exceptions, but bear in mind that in a practical context (i.e., we wanted to use this function in production), where we may receive all sort of data, we would have to better handle data types and other unique exceptions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, train_size, validation_size):\n",
    "    '''\n",
    "    Function: \n",
    "\n",
    "            Generates train, validation and test sets from arrays of features and targets.\n",
    "\n",
    "    Inputs: \n",
    "\n",
    "            X: array containing the features \n",
    "            y: array containing the targets/labels\n",
    "            train_size: percentage of data to be used for training (takes values beween 0-1)\n",
    "            validation_size: percentage of the remaining data (1 - tain_size) to be used for validating (takes values beween 0-1)\n",
    "\n",
    "    Outputs: \n",
    "\n",
    "             1. array of features for training of size: 'train_size' * len(data)\n",
    "             2. array of targets for training of size: 'train_size' * len(data)\n",
    "             3. array of features for validating of size: (1 - 'train_size') * 'validation_size' * len(data) \n",
    "             4. array of targets for validating of size: (1 - 'train_size') * 'validation_size' * len(data) \n",
    "             5. array of features for testing of size: (1 - 'train_size') * (1 - 'validation_size') * len(data) \n",
    "             6. array of targets for testing of size: (1 - 'train_size') * (1 - 'validation_size') * len(data) \n",
    "    '''\n",
    "    \n",
    "    # check conditions \n",
    "    allowed_dtypes = [np.ndarray] \n",
    "    # check the input data types\n",
    "    if type(X) not in allowed_dtypes:\n",
    "        raise TypeError ('Features should be a numpy.ndarray')\n",
    "    if type(y) not in allowed_dtypes:\n",
    "        raise TypeError ('Targets should be a numpy.ndarray')\n",
    "    # check that th arrays are of the same lenght \n",
    "    if len(X) != len(y):\n",
    "        raise ValueError (f'Targets and features should have the same length. Received sizes ({len(X)}, {len(y)}).')\n",
    "    # check the splits\n",
    "    if train_size == 0:\n",
    "        warnings.warn(f'Only validation and test sets were created.', stacklevel=2)\n",
    "    if validation_size == 0:\n",
    "        warnings.warn(f'No validation and test sets were created.', stacklevel=2)\n",
    "\n",
    "    # create a random index of integers \n",
    "    ind = random.sample(range(0, len(X)), int(len(X)*train_size))\n",
    "    #create a mask \n",
    "    mask = np.ones(len(X), dtype=bool)\n",
    "    mask[ind] = False\n",
    "    # slice the features for the trainig set by the indexes generated\n",
    "    X_train = X[ind]\n",
    "    # slice the features for the test set by the mask generated\n",
    "    X_test = X[mask] \n",
    "    # slice the tragets for the train set by the indexes generated\n",
    "    y_train = y[ind]\n",
    "    # slice the targets for the test set by the mask generated\n",
    "    y_test = y[mask] \n",
    "    # create second index of integers \n",
    "    ind_2 = random.sample(range(0, len(X_test)), int(len(X_test)*validation_size)) \n",
    "    #create second mask \n",
    "    mask_2 = np.ones(len(X_test), dtype=bool)\n",
    "    mask_2[ind_2] = False\n",
    "    # slice the features for the validation set by the indexes generated\n",
    "    X_val = X_test[ind_2]\n",
    "    # slice the features for the test set by the mask generated\n",
    "    X_test = X_test[mask_2] \n",
    "    # slice the targets for the validation set by the indexes generated\n",
    "    y_val = y_test[ind_2]\n",
    "    # slice the targets for the test set by the mask generated\n",
    "    y_test = y_test[mask_2] \n",
    "    # return the sets\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we pass some 'wrong' arguments to the function and check its responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Features should be a numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aav\\OneDrive - Lumera AB\\Documents\\Github\\Book\\Python\\Chapter 16\\Chapter_16_exercises.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aav/OneDrive%20-%20Lumera%20AB/Documents/Github/Book/Python/Chapter%2016/Chapter_16_exercises.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# testing a wrong type of features input\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/aav/OneDrive%20-%20Lumera%20AB/Documents/Github/Book/Python/Chapter%2016/Chapter_16_exercises.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m X_train, y_train, X_val, y_val, X_test, y_test \u001b[39m=\u001b[39m train_test_split(\u001b[39m'\u001b[39;49m\u001b[39mstring\u001b[39;49m\u001b[39m'\u001b[39;49m, iris\u001b[39m.\u001b[39;49mtarget, \u001b[39m0\u001b[39;49m, \u001b[39m1\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\aav\\OneDrive - Lumera AB\\Documents\\Github\\Book\\Python\\Chapter 16\\Chapter_16_exercises.ipynb Cell 12\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(X, y, train_size, validation_size)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aav/OneDrive%20-%20Lumera%20AB/Documents/Github/Book/Python/Chapter%2016/Chapter_16_exercises.ipynb#X32sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# check the input data types\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aav/OneDrive%20-%20Lumera%20AB/Documents/Github/Book/Python/Chapter%2016/Chapter_16_exercises.ipynb#X32sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(X) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m allowed_dtypes:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/aav/OneDrive%20-%20Lumera%20AB/Documents/Github/Book/Python/Chapter%2016/Chapter_16_exercises.ipynb#X32sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mFeatures should be a numpy.ndarray\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aav/OneDrive%20-%20Lumera%20AB/Documents/Github/Book/Python/Chapter%2016/Chapter_16_exercises.ipynb#X32sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(y) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m allowed_dtypes:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aav/OneDrive%20-%20Lumera%20AB/Documents/Github/Book/Python/Chapter%2016/Chapter_16_exercises.ipynb#X32sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mTargets should be a numpy.ndarray\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Features should be a numpy.ndarray"
     ]
    }
   ],
   "source": [
    "# testing a wrong type of features input\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = train_test_split('string', iris.target, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Targets and features should have the same length. Received sizes (100, 150).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aav\\OneDrive - Lumera AB\\Documents\\Github\\Book\\Python\\Chapter 16\\Chapter_16_exercises.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aav/OneDrive%20-%20Lumera%20AB/Documents/Github/Book/Python/Chapter%2016/Chapter_16_exercises.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# testing features and target arrays of different sizes\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/aav/OneDrive%20-%20Lumera%20AB/Documents/Github/Book/Python/Chapter%2016/Chapter_16_exercises.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m X_train, y_train, X_val, y_val, X_test, y_test \u001b[39m=\u001b[39m train_test_split(np\u001b[39m.\u001b[39;49marange(\u001b[39m100\u001b[39;49m), iris\u001b[39m.\u001b[39;49mtarget, \u001b[39m0.7\u001b[39;49m, \u001b[39m0.5\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\aav\\OneDrive - Lumera AB\\Documents\\Github\\Book\\Python\\Chapter 16\\Chapter_16_exercises.ipynb Cell 13\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(X, y, train_size, validation_size)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aav/OneDrive%20-%20Lumera%20AB/Documents/Github/Book/Python/Chapter%2016/Chapter_16_exercises.ipynb#X33sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# check that th arrays are of the same lenght \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aav/OneDrive%20-%20Lumera%20AB/Documents/Github/Book/Python/Chapter%2016/Chapter_16_exercises.ipynb#X33sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(X) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(y):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/aav/OneDrive%20-%20Lumera%20AB/Documents/Github/Book/Python/Chapter%2016/Chapter_16_exercises.ipynb#X33sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m (\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTargets and features should have the same length. Received sizes (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(X)\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(y)\u001b[39m}\u001b[39;00m\u001b[39m).\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aav/OneDrive%20-%20Lumera%20AB/Documents/Github/Book/Python/Chapter%2016/Chapter_16_exercises.ipynb#X33sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# check the splits\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aav/OneDrive%20-%20Lumera%20AB/Documents/Github/Book/Python/Chapter%2016/Chapter_16_exercises.ipynb#X33sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mif\u001b[39;00m train_size \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: Targets and features should have the same length. Received sizes (100, 150)."
     ]
    }
   ],
   "source": [
    "# testing features and target arrays of different sizes\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = train_test_split(np.arange(100), iris.target, 0.7, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aav\\AppData\\Local\\Temp\\ipykernel_8564\\3533856617.py:2: UserWarning: Only validation and test sets were created.\n",
      "  X_train, y_train, X_val, y_val, X_test, y_test = train_test_split(iris.data, iris.target, 0, 1)\n"
     ]
    }
   ],
   "source": [
    "# testing an input == 0 for training_size\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = train_test_split(iris.data, iris.target, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aav\\AppData\\Local\\Temp\\ipykernel_8564\\1890066586.py:2: UserWarning: No validation and test sets were created.\n",
      "  X_train, y_train, X_val, y_val, X_test, y_test = train_test_split(iris.data, iris.target, 0.7, 0)\n"
     ]
    }
   ],
   "source": [
    "# testing an input == 0 for validation_size\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = train_test_split(iris.data, iris.target, 0.7, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement train_test_split version with stratified sampling, i.e. sample such that you have an approximately equal distribution of class labels in each output set.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In exercise 1 we saw that, by just randomly sample the data, we may create imbalances in the classes. In this exercise we build a function that deals with that and returns training, validation and test sets containing the same percentage of target class as in the dataset provided. \n",
    "We will use a slightly different approach in this case and start by creating a unique dataset containing features and targets. <br> We also count the number of target classes (unique labels) and their percentage in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique classes: 3\n",
      "Classes: {0: 0.3333333333333333, 1: 0.3333333333333333, 2: 0.3333333333333333}\n"
     ]
    }
   ],
   "source": [
    "# let us start by creating one array with features and targets together\n",
    "all = np.c_[iris.data, iris.target]\n",
    "# we count the number of unique classes (targets) we have\n",
    "n_classes = len(np.unique(iris.target))\n",
    "print(f'Number of unique classes: {n_classes}') \n",
    "\n",
    "# return the number of instances per each class\n",
    "data_per_class = np.unique(iris.target, return_counts=True)[1]\n",
    "# create a dictionary that stores 'class': '% of that class in the data'\n",
    "classes = {}\n",
    "for i in range(n_classes):\n",
    "    classes[i] = data_per_class[i]/len(iris.data)\n",
    "\n",
    "print(f'Classes: {classes}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we gather those labels together and extract a dataset for each target class, in this case, one for setosa, one for virginica and one for versicolor. <br> We store each 'unique label' dataset in a list of datasets (lists), which we call *list_classes*: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the array to a list\n",
    "all = list(all)\n",
    "# sort by class\n",
    "all.sort(key = lambda x: x[-1])\n",
    "# create a list of lists containing each class \n",
    "list_classes = []\n",
    "# start and finish index to slice the data \n",
    "s = 0\n",
    "f = 0\n",
    "#for each class in the data slice its data and append it to list_classes\n",
    "for c in classes.keys():\n",
    "    f+= int(classes[c]*len(iris.data))\n",
    "    class_inst = all[s:f]\n",
    "    s+= int(classes[c]*len(iris.data))\n",
    "    list_classes.append(class_inst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have separated the classes (which in most cases will have a different number of samples), each one in one dataset, we can use the same *train_size* and *validation_size* to sample from those datasets, one at the time, and this will allow us to keep the same representation of classes we had in the original data (*stratification*). <br> We append the setosa, viginica and versicolor samples to *train_array*, *val_array*, *test_array*, each class having its specific train, validation and test splits in each of these lists:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "train_size = 0.7\n",
    "validation_size = 0.5\n",
    "train_array = []\n",
    "val_array = []\n",
    "test_array = []\n",
    "for c in list_classes:  \n",
    "    # convert list to array\n",
    "    c = np.array(c)  \n",
    "    # create a random index of integers \n",
    "    ind = random.sample(range(0, len(c)), int(len(c)*train_size))\n",
    "    #create a mask \n",
    "    mask = np.ones(len(c), dtype=bool)\n",
    "    mask[ind] = False\n",
    "    # slice the features for the trainig set by the indexes generated\n",
    "    X_train = c[ind]\n",
    "    # slice the features for the test set by the mask generated\n",
    "    X_test = c[mask] \n",
    "    # create second index of integers \n",
    "    ind_2 = random.sample(range(0, len(X_test)), int(len(X_test)*validation_size)) \n",
    "    #create second mask \n",
    "    mask_2 = np.ones(len(X_test), dtype=bool)\n",
    "    mask_2[ind_2] = False\n",
    "    # slice the features for the validation set by the indexes generated\n",
    "    X_val = X_test[ind_2]\n",
    "    # slice the features for the test set by the mask generated\n",
    "    X_test = X_test[mask_2] \n",
    "    \n",
    "    # appending the train, validation and test sets for each class\n",
    "    train_array.append(X_train)\n",
    "    val_array.append(X_val)\n",
    "    test_array.append(X_test)\n",
    "\n",
    "# this will be equal to the number of classes, since we are generating a dataset for each one\n",
    "print(len(train_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We concatenate those arrays to create a single train, validation and test array and we extract the first to the penultimate column to gather the features and the last column to separate the targets (remember we had previously combined our X and y along the first axis to generate a single array):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the datasets and separates the features from the targets\n",
    "train = np.concatenate(train_array)\n",
    "X_train = train[:, :-1]\n",
    "y_train = train[:, -1]\n",
    "validation = np.concatenate(val_array)\n",
    "X_val = validation[:, :-1]\n",
    "y_val = validation[:, -1]\n",
    "test = np.concatenate(test_array)\n",
    "X_test = test[:, :-1]\n",
    "y_test = test[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above scripts result in the below function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_strat(X, y, train_size, validation_size):\n",
    "        '''\n",
    "    Function: \n",
    "\n",
    "            Generates stratfied train, validation and test sets from arrays of features and targets.\n",
    "\n",
    "    Inputs: \n",
    "\n",
    "            X: array containing the features \n",
    "            y: array containing the targets/labels\n",
    "            train_size: percentage of data to be used for training (takes values beween 0-1)\n",
    "            validation_size: percentage of the remaining data (1 - tain_size) to be used for validating (takes values beween 0-1)\n",
    "\n",
    "    Outputs: \n",
    "\n",
    "             1. array of features for training of size: 'train_size' * len(data)\n",
    "             2. array of targets for training of size: 'train_size' * len(data)\n",
    "             3. array of features for validating of size: (1 - 'train_size') * 'validation_size' * len(data) \n",
    "             4. array of targets for validating of size: (1 - 'train_size') * 'validation_size' * len(data) \n",
    "             5. array of features for testing of size: (1 - 'train_size') * (1 - 'validation_size') * len(data) \n",
    "             6. array of targets for testing of size: (1 - 'train_size') * (1 - 'validation_size') * len(data) \n",
    "    '''\n",
    "\n",
    "        all = np.c_[X, y]\n",
    "        # we count the number of unique classes (targets) we have\n",
    "        n_classes = len(np.unique(y))\n",
    "\n",
    "        # return the number of instances per each class\n",
    "        data_per_class = np.unique(y, return_counts=True)[1]\n",
    "        # create a dictionary that stores 'class': '% of that class in the data'\n",
    "        classes = {}\n",
    "        for i in range(n_classes):\n",
    "                classes[i] = data_per_class[i]/len(X)\n",
    "        train_array = []\n",
    "        val_array = []\n",
    "        test_array = []\n",
    "\n",
    "        # convert the array to a list\n",
    "        all = list(all)\n",
    "        # sort by class\n",
    "        all.sort(key = lambda x: x[-1])\n",
    "        # create a list of lists contianing each class \n",
    "        list_classes = []\n",
    "        # start and finish index to slice the data \n",
    "        s = 0\n",
    "        f = 0\n",
    "        #for each class in the data slice its data and append it to list_classes\n",
    "        for c in classes.keys():\n",
    "                f+= int(classes[c]*len(X))\n",
    "                class_inst = all[s:f]\n",
    "                s+= int(classes[c]*len(X))\n",
    "                list_classes.append(class_inst)\n",
    "\n",
    "        for c in list_classes:  \n",
    "                # convert list to array\n",
    "                c = np.array(c)  \n",
    "                # create a random index of integers \n",
    "                ind = random.sample(range(0, len(c)), int(len(c)*train_size))\n",
    "                #create a mask \n",
    "                mask = np.ones(len(c), dtype=bool)\n",
    "                mask[ind] = False\n",
    "                # slice the features for the trainig set by the indexes generated\n",
    "                X_train = c[ind]\n",
    "                # slice the features for the test set by the mask generated\n",
    "                X_test = c[mask] \n",
    "                # create second index of integers \n",
    "                ind_2 = random.sample(range(0, len(X_test)), int(len(X_test)*validation_size)) \n",
    "                #create second mask \n",
    "                mask_2 = np.ones(len(X_test), dtype=bool)\n",
    "                mask_2[ind_2] = False\n",
    "                # slice the features for the validation set by the indexes generated\n",
    "                X_val = X_test[ind_2]\n",
    "                # slice the features for the test set by the mask generated\n",
    "                X_test = X_test[mask_2] \n",
    "                # appending the train, validation and test sets for each class\n",
    "                train_array.append(X_train)\n",
    "                val_array.append(X_val)\n",
    "                test_array.append(X_test)\n",
    "\n",
    "        # concatenate the datasets and separates the features from the targets\n",
    "        train = np.concatenate(train_array)\n",
    "        X_train = train[:, :-1]\n",
    "        y_train = train[:, -1]\n",
    "        validation = np.concatenate(val_array)\n",
    "        X_val = validation[:, :-1]\n",
    "        y_val = validation[:, -1]\n",
    "        test = np.concatenate(test_array)\n",
    "        X_test = test[:, :-1]\n",
    "        y_test = test[:, -1]\n",
    "\n",
    "        return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks quite intimidating when put it all together, but hopefully now we know what each line does. Also, the function still runs very fast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function running time: 0.0009734631\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# unpack the function varibales in the train, validation and test sets\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = train_test_split_strat(iris.data, iris.target, train_size = 0.7, validation_size = 0.4)\n",
    "print(f'Function running time: {(time.time() - start):.10f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features for training: 105\n",
      "Number of targets for training: 105\n",
      "Number of features for validating: 18\n",
      "Number of targets for validating: 18\n",
      "Number of features for testing: 27\n",
      "Number of targets for testing: 27\n"
     ]
    }
   ],
   "source": [
    "# print the number of samples per dataset\n",
    "print(f'Number of features for training: {len(X_train)}')\n",
    "print(f'Number of targets for training: {len(y_train)}')\n",
    "print(f'Number of features for validating: {len(X_val)}')\n",
    "print(f'Number of targets for validating: {len(y_val)}')\n",
    "print(f'Number of features for testing: {len(X_test)}')\n",
    "print(f'Number of targets for testing: {len(y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we print the number of unique labels in the test set and, as desired, this time we have the same number of labels in this set, in line with the original dataset splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1., 2.]), array([9, 9, 9], dtype=int64))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count of unique labels in the test dataset\n",
    "np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our final function\n",
    "This is the final train_test_split function with stratification and (some) errors handling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_strat(X, y, train_size, validation_size):\n",
    "        '''\n",
    "    Function: \n",
    "\n",
    "            Generates startified train, validation and test sets from arrays of features and targets.\n",
    "\n",
    "    Inputs: \n",
    "\n",
    "            X: array containing the features \n",
    "            y: array containing the targets/labels\n",
    "            train_size: percentage of data to be used for training (takes values beween 0-1)\n",
    "            validation_size: percentage of the remaining data (1 - tain_size) to be used for validating (takes values beween 0-1)\n",
    "\n",
    "    Outputs: \n",
    "\n",
    "             1. array of features for training of size: 'train_size' * len(data)\n",
    "             2. array of targets for training of size: 'train_size' * len(data)\n",
    "             3. array of features for validating of size: (1 - 'train_size') * 'validation_size' * len(data) \n",
    "             4. array of targets for validating of size: (1 - 'train_size') * 'validation_size' * len(data) \n",
    "             5. array of features for testing of size: (1 - 'train_size') * (1 - 'validation_size') * len(data) \n",
    "             6. array of targets for testing of size: (1 - 'train_size') * (1 - 'validation_size') * len(data) \n",
    "    '''\n",
    "\n",
    "        # check conditions \n",
    "        allowed_dtypes = [np.ndarray] \n",
    "        # check the input data types\n",
    "        if type(X) not in allowed_dtypes:\n",
    "                raise TypeError ('Features should be a numpy.ndarray')\n",
    "        if type(y) not in allowed_dtypes:\n",
    "                raise TypeError ('Targets should be a numpy.ndarray')\n",
    "         # check that th arrays are of the same lenght \n",
    "        if len(X) != len(y):\n",
    "                raise ValueError (f'Targets and features should have the same length. Received sizes ({len(X)}, {len(y)}).')\n",
    "        # check the splits\n",
    "        if train_size == 0:\n",
    "                warnings.warn(f'Only validation and test sets were created.', stacklevel=2)\n",
    "        if validation_size == 0:\n",
    "                warnings.warn(f'No validation and test sets were created.', stacklevel=2)\n",
    "\n",
    "        all = np.c_[X, y]\n",
    "        # we count the number of unique classes (targets) we have\n",
    "        n_classes = len(np.unique(y))\n",
    "\n",
    "        # return the number of instances per each class\n",
    "        data_per_class = np.unique(y, return_counts=True)[1]\n",
    "        # create a dictionary that stores 'class': '% of that class in the data'\n",
    "        classes = {}\n",
    "        for i in range(n_classes):\n",
    "                classes[i] = data_per_class[i]/len(X)\n",
    "        train_array = []\n",
    "        val_array = []\n",
    "        test_array = []\n",
    "\n",
    "        # convert the array to a list\n",
    "        all = list(all)\n",
    "        # sort by class\n",
    "        all.sort(key = lambda x: x[-1])\n",
    "        # create a list of lists contianing each class \n",
    "        list_classes = []\n",
    "        # start and finish index to slice the data \n",
    "        s = 0\n",
    "        f = 0\n",
    "        #for each class in the data slice its data and append it to list_classes\n",
    "        for c in classes.keys():\n",
    "                f+= int(classes[c]*len(X))\n",
    "                class_inst = all[s:f]\n",
    "                s+= int(classes[c]*len(X))\n",
    "                list_classes.append(class_inst)\n",
    "\n",
    "        for c in list_classes:  \n",
    "                # convert list to array\n",
    "                c = np.array(c)  \n",
    "                # create a random index of integers \n",
    "                ind = random.sample(range(0, len(c)), int(len(c)*train_size))\n",
    "                #create a mask \n",
    "                mask = np.ones(len(c), dtype=bool)\n",
    "                mask[ind] = False\n",
    "                # slice the features for the trainig set by the indexes generated\n",
    "                X_train = c[ind]\n",
    "                # slice the features for the test set by the mask generated\n",
    "                X_test = c[mask] \n",
    "                # create second index of integers \n",
    "                ind_2 = random.sample(range(0, len(X_test)), int(len(X_test)*validation_size)) \n",
    "                #create second mask \n",
    "                mask_2 = np.ones(len(X_test), dtype=bool)\n",
    "                mask_2[ind_2] = False\n",
    "                # slice the features for the validation set by the indexes generated\n",
    "                X_val = X_test[ind_2]\n",
    "                # slice the features for the test set by the mask generated\n",
    "                X_test = X_test[mask_2] \n",
    "                # appending the train, validation and test sets for each class\n",
    "                train_array.append(X_train)\n",
    "                val_array.append(X_val)\n",
    "                test_array.append(X_test)\n",
    "\n",
    "        # concatenate the datasets and separates the features from the targets\n",
    "        train = np.concatenate(train_array)\n",
    "        X_train = train[:, :-1]\n",
    "        y_train = train[:, -1]\n",
    "        validation = np.concatenate(val_array)\n",
    "        X_val = validation[:, :-1]\n",
    "        y_val = validation[:, -1]\n",
    "        test = np.concatenate(test_array)\n",
    "        X_test = test[:, :-1]\n",
    "        y_test = test[:, -1]\n",
    "\n",
    "        return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tf-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d9f0d90cc8427aff927702ddc713a23db8aebe0fdc8c83004a87727c2ec16f07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
